# CS472
From Syllabus:

Machine learning is about building predictive or descriptive models automatically from data. There are two central challenges in machine learning. The first is generalizing from data to future situations. A model that performs very well on past data may nonetheless perform very poorly on unseen examples, a phenomenon known as "overfitting". The second challenge is building models efficiently, especially in cases where the dataset is very large and the patterns are complex. We will cover standard methodologies, models, and algorithms for machine learning. Specific topics include decision trees, instance-based learning, linear classifiers, probabilistic classifiers, support vector machines, deep learning, and learning theory.

This course covers standard methodologies, models, and algorithms for machine learning. Specific topics include decision trees, instance-based learning, linear classifiers, probabilistic classifiers, support vector machines, and learning theory. Especially, we will spend a large amount of time for deep learning, the recent approach to machine learning that has achieved very high performance for tasks in different application domains (e.g., computer vision, natural language processing).

Upon successful completion of the course, students will be able to:

- demonstrate facility with the cycle of machine learning model development, including training, developing, and testing;
- demonstrate facility with the fundamental concepts and problems in machine learning, including (hyper-)parameters, loss functions, overfitting, underfitting, cross-validation, regularization, evaluation measures;
- demonstrate facility with different types of learning, i.e., supervised learning, semi-supervised learning, and unsupervised learning;
- demonstrate facility with traditional machine learning methods, i.e., decision trees, nearest neighbor, perceptron, linear and logistic regression, and support vector machines;
- demonstrate facility with the basic concepts in deep learning, i.e., feed-forward networks, activation functions, computational graphs, back-propagation, and (stochastic) gradient decent;
- demonstrate facility with advanced deep learning models, including convolutional neural networks, recurrent neural networks, residual models, transformers, and their applications to different types of data;
- be able to identify machine learning problems and design appropriate features and models to solve those problems;
- be able to leverage available machine learning frameworks (pytorch, scikit-learn) to implement models and apply them for data of interested domains;
- be able to analyze the operation/outputs of basic machine learning models for debugging and performance improvement purposes.

Taught by Prof. Thien Huu Nguyen at University of Oregon.
